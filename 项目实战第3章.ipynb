{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THINKING:\n",
    "1.如何使用用户标签来指导业务（如何提升业务）\n",
    "答：系统刚上线阶段，需要冷启动，拉新，这时可以根据用户注册时填写的信息包括人口统计信息（例如：年龄，工作种类，性别等）来进行推荐，也可根据获得用户的场景来（例如，用户为大学校园内的拉新活动获得）来进行推荐；拉新阶段过后，用户产生用户行为数据，可以根据UGC和PGC来进行相应的个性化推荐，也可以进行热门推荐等多种推荐同时进行，保证用户黏度，提高用户留存率；如果产品对用户来说为阶段性使用产品，则需要对关键的用户流失点进行预测，统计流失率，对留存用户数量有一个大致的掌握。\n",
    "\n",
    "2.如果给你一堆用户数据，没有打标签。你该如何处理（如何打标签）\n",
    "答：用户数据量小的情况下可以使用专家评分方式进行打标签，如果用户数量有一定的规模，则可以对用户的行为数据进行聚类分析，然后根据类别来判断分析同一个类别中的用户所具有的特征，对这些用户的特性进行解释，并产生用户标签。\n",
    "\n",
    "3.准确率和精确率有何不同（评估指标）\n",
    "答：准确率是预测结果中预测分类正确结果的比例，而精确率是指预测为YES的类别中真正为YES的概率。\n",
    "\n",
    "4.如果你使用大众点评，想要给某个餐厅打标签。这时系统可以自动提示一些标签，你会如何设计（标签推荐）\n",
    "答：一是根据商店自身的性质来分析，分析餐厅菜品种类，分析拥有与之相近菜品种类的餐厅，将后者的标签推荐给当前餐厅，二是根据该餐厅的其他用户行为进行分析，计算出其他用户喜欢给该餐厅打的标签并进行推荐，三是根据用户自身行为，该用户对同类餐厅常用的标签也可以进行推荐。\n",
    "\n",
    "\n",
    "5.我们今天使用了10种方式来解MNIST，这些方法有何不同？你还有其他方法来解决MNIST识别问题么（分类方法）\n",
    "答：这些算法模型主要包括决策树模型，逻辑回归，高维空间中的支持向量机，神经网络模型，先验概率分布朴素贝叶斯模型等这么几大类，TPOT则是一种大而全的最优模型搜索工具。还可以通过主成分分析之后进行softmax分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小为 437593.\n",
      "设置tag的人数 1867.\n",
      "数据加载完成\n",
      "\n",
      "训练集样本数 1860, 测试集样本数 1793\n",
      "user_tags, tag_items, user_items初始化完成.\n",
      "user_tags大小 1860, tag_items大小 36884, user_items大小 1860\n",
      "推荐结果评估\n",
      "  N        精确率        召回率\n",
      "  5      1.008%      0.431%\n",
      " 10      0.761%      0.652%\n",
      " 20      0.549%      0.940%\n",
      " 40      0.402%      1.376%\n",
      " 60      0.328%      1.687%\n",
      " 80      0.297%      2.033%\n",
      "100      0.269%      2.306%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import operator\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"G:\\\\python_lesson\\\\L3-code\\\\code\\\\delicious-2k\\\\user_taggedbookmarks-timestamps.dat\"\n",
    "records = {}\n",
    "train_data = dict()\n",
    "test_data = dict()\n",
    "# 用户标签，商品标签\n",
    "user_tags = dict()\n",
    "tag_items = dict()\n",
    "user_items = dict()\n",
    "\n",
    "item_tags = dict()\n",
    "tag_users = dict()\n",
    "item_users = dict()\n",
    "\n",
    "\n",
    "def precisionAndRecall(N):\n",
    "    hit = 0\n",
    "    h_recall = 0\n",
    "    h_precision = 0\n",
    "    for user, items in test_data.items():\n",
    "        if user not in train_data:\n",
    "            continue\n",
    "        rank = recommend(user, N)\n",
    "        for item, rui in rank:\n",
    "            if item in items:\n",
    "                hit = hit + 1\n",
    "        h_recall = h_recall + len(items)\n",
    "        h_precision = h_precision + N\n",
    "    return (hit / (h_precision * 1.0)), (hit / (h_recall * 1.0))\n",
    "\n",
    "\n",
    "def recommend(user, N):\n",
    "    recommend_items = dict()\n",
    "    tagged_items = user_items[user]\n",
    "    for tag, wut in user_tags[user].items():\n",
    "        # print(self.user_tags[user].items())\n",
    "        for item, wti in tag_items[tag].items():\n",
    "            if item in tagged_items:\n",
    "                continue\n",
    "            #norm = len(tag_users[tag].items()) * len(user_tags[user].items())\n",
    "            norm=math.log(len(tag_users[tag].items())+1)\n",
    "            if item not in recommend_items:\n",
    "                recommend_items[item] = wut * wti / norm\n",
    "            else:\n",
    "                recommend_items[item] = recommend_items[item] + wut * wti / norm\n",
    "    return sorted(recommend_items.items(), key=operator.itemgetter(1), reverse=True)[0:N]\n",
    "\n",
    "\n",
    "def testRecommend():\n",
    "    print(\"推荐结果评估\")\n",
    "    print(\"%3s %10s %10s\" % ('N', \"精确率\", '召回率'))\n",
    "    for n in [5, 10, 20, 40, 60, 80, 100]:\n",
    "        precision, recall = precisionAndRecall(n)\n",
    "        print(\"%3d %10.3f%% %10.3f%%\" % (n, precision * 100, recall * 100))\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    for i in range(len(df)):\n",
    "        uid = df['userID'][i]\n",
    "        iid = df['bookmarkID'][i]\n",
    "        tag = df['tagID'][i]\n",
    "        records.setdefault(uid, {})\n",
    "        records[uid].setdefault(iid, [])\n",
    "        records[uid][iid].append(tag)\n",
    "    print(\"数据集大小为 %d.\" % (len(df)))\n",
    "    print(\"设置tag的人数 %d.\" % (len(records)))\n",
    "    print(\"数据加载完成\\n\")\n",
    "\n",
    "\n",
    "def train_test_split(ratio, seed=100):\n",
    "    random.seed(seed)\n",
    "    for u in records.keys():\n",
    "        for i in records[u].keys():\n",
    "            # ratio比例设置为测试集\n",
    "            if random.random() < ratio:\n",
    "                test_data.setdefault(u, {})\n",
    "                test_data[u].setdefault(i, [])\n",
    "                for t in records[u][i]:\n",
    "                    test_data[u][i].append(t)\n",
    "            else:\n",
    "                train_data.setdefault(u, {})\n",
    "                train_data[u].setdefault(i, [])\n",
    "                for t in records[u][i]:\n",
    "                    train_data[u][i].append(t)\n",
    "    print(\"训练集样本数 %d, 测试集样本数 %d\" % (len(train_data), len(test_data)))\n",
    "\n",
    "\n",
    "def addValueToMat(mat, index, item, value=1):\n",
    "    if index not in mat:\n",
    "        mat.setdefault(index, {})\n",
    "        mat[index].setdefault(item, value)\n",
    "    else:\n",
    "        if item not in mat[index]:\n",
    "            mat[index][item] = value\n",
    "        else:\n",
    "            mat[index][item] += value\n",
    "\n",
    "\n",
    "def initStat():\n",
    "    records = train_data\n",
    "    for u, items in records.items():\n",
    "        for i, tags in items.items():\n",
    "            for tag in tags:\n",
    "                addValueToMat(user_tags, u, tag, 1)\n",
    "                addValueToMat(tag_items, tag, i, 1)\n",
    "                addValueToMat(user_items, u, i, 1)\n",
    "                addValueToMat(tag_users,tag,u,1)\n",
    "    print(\"user_tags, tag_items, user_items初始化完成.\")\n",
    "    print(\"user_tags大小 %d, tag_items大小 %d, user_items大小 %d\" % (len(user_tags), len(tag_items), len(user_items)))\n",
    "\n",
    "\n",
    "# 数据加载\n",
    "load_data()\n",
    "# 训练集，测试集拆分，20%测试集\n",
    "train_test_split(0.2)\n",
    "initStat()\n",
    "testRecommend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐结果评估\n",
    "  N        精确率        召回率\n",
    "  5      0.829%      0.355%\n",
    " 10      0.633%      0.542%\n",
    " 20      0.512%      0.877%\n",
    " 40      0.381%      1.304%\n",
    " 60      0.318%      1.635%\n",
    " 80      0.276%      1.893%\n",
    "100      0.248%      2.124%\n",
    "\n",
    "NormTagBased推荐结果评估:\n",
    "\n",
    " N        精确率        召回率\n",
    "  5      0.907%      0.388%\n",
    " 10      0.638%      0.546%\n",
    " 20      0.507%      0.868%\n",
    " 40      0.356%      1.218%\n",
    " 60      0.287%      1.476%\n",
    " 80      0.255%      1.750%\n",
    "100      0.241%      2.061%\n",
    "\n",
    "TagBased-TFIDF推荐结果评估:\n",
    "  N        精确率        召回率\n",
    "  5      1.008%      0.431%\n",
    " 10      0.761%      0.652%\n",
    " 20      0.549%      0.940%\n",
    " 40      0.402%      1.376%\n",
    " 60      0.328%      1.687%\n",
    " 80      0.297%      2.033%\n",
    "100      0.269%      2.306%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tpot预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lyr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据探索：\n",
      "nan\n",
      "True\n",
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=120.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8473347547974415\n",
      "Generation 2 - Current best internal CV score: 0.8518572550779935\n",
      "Generation 3 - Current best internal CV score: 0.8518572550779935\n",
      "Generation 4 - Current best internal CV score: 0.8518572550779935\n",
      "Generation 5 - Current best internal CV score: 0.8548423297048592\n",
      "Best pipeline: ExtraTreesClassifier(MaxAbsScaler(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False)), bootstrap=False, criterion=entropy, max_features=0.4, min_samples_leaf=3, min_samples_split=5, n_estimators=100)\n",
      "[0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 0]\n",
      "0.7937219730941704\n",
      "353\n",
      "预测准确率：\n",
      "0.8444976076555024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "titanic_train_data = pd.read_csv( 'G:\\\\python_lesson\\\\titanic\\\\train.csv')\n",
    "titanic_test_data=pd.read_csv(\"G:\\\\python_lesson\\\\titanic\\\\test.csv\")\n",
    "real_result=pd.read_csv(\"G:\\\\python_lesson\\\\titanic\\\\gender_submission.csv\")\n",
    "print(\"训练集数据探索：\")\n",
    "#print(titanic_train_data.info())\n",
    "'''\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['male','female'])\n",
    "a=le.transform(titanic_train_data['Sex'].values.tolist())'''\n",
    "print(titanic_train_data.iloc[61,11])\n",
    "print(str(titanic_train_data.iloc[61,11]) =='nan')\n",
    "\n",
    "def caculate_age(sex,Pclass,Survived):\n",
    "    a=titanic_train_data[(titanic_train_data['Sex'] == sex)&(titanic_train_data['Pclass'] == Pclass)&(titanic_train_data['Survived'] == Survived)]['Age'].mean()\n",
    "    if a==0:\n",
    "        a=titanic_train_data[(titanic_train_data['Sex'] == sex)&(titanic_train_data['Pclass'] == Pclass)]['Age'].mean()\n",
    "        if a==0:\n",
    "            a = titanic_train_data[(titanic_train_data['Sex'] == sex)]['Age'].mean()\n",
    "    #print(a)\n",
    "    return a\n",
    "def caculate_test_age(sex,Pclass):\n",
    "    a=titanic_train_data[(titanic_train_data['Sex'] == sex)&(titanic_train_data['Pclass'] == Pclass)]['Age'].mean()\n",
    "    if a==0:\n",
    "        a = titanic_train_data[(titanic_train_data['Sex'] == sex)]['Age'].mean()\n",
    "    #print(a)\n",
    "    return a\n",
    "def caculate_fare(sex,Pclass):\n",
    "    b=titanic_train_data[(titanic_train_data['Sex'] == sex)&(titanic_train_data['Pclass'] == Pclass)]['Fare'].mean()\n",
    "    if b==0:\n",
    "        b=titanic_train_data[(titanic_train_data['Sex'] == sex)]['Fare'].mean()\n",
    "    #print(b)\n",
    "    return b\n",
    "'''\n",
    "def caculate_Embarked(sex,Survived):\n",
    "    b=titanic_train_data[(titanic_train_data['Sex'] == sex)&(titanic_train_data['Survived'] == Survived)]['Embarked'].median()\n",
    "    if b==0:\n",
    "        b=titanic_train_data[(titanic_train_data['Sex'] == sex)]['Embarked'].median()\n",
    "    print(b)\n",
    "    return b\n",
    "'''\n",
    "def encode(oridata):\n",
    "    for i in range(0,oridata.shape[0]):\n",
    "        for j in range(0,oridata.shape[1]):\n",
    "            #如果是sex列\n",
    "            if j==4:\n",
    "                if oridata.iloc[i,j]=='male':\n",
    "                    oridata.iloc[i,j]=1\n",
    "                else:\n",
    "                    oridata.iloc[i, j] = 0\n",
    "            if j==11:\n",
    "                if oridata.iloc[i,j]=='S':\n",
    "                    oridata.iloc[i, j] = 0\n",
    "                if oridata.iloc[i,j]=='C':\n",
    "                    oridata.iloc[i, j] = 1\n",
    "                if oridata.iloc[i, j] == 'Q':\n",
    "                    oridata.iloc[i, j] = 2\n",
    "            else:\n",
    "                continue\n",
    "    return oridata\n",
    "def encode_test(oridata):\n",
    "    for i in range(0,oridata.shape[0]):\n",
    "        for j in range(0,oridata.shape[1]):\n",
    "            #如果是sex列\n",
    "            if j==3:\n",
    "                if oridata.iloc[i,j]=='male':\n",
    "                    oridata.iloc[i,j]=1\n",
    "                else:\n",
    "                    oridata.iloc[i, j] = 0\n",
    "            if j==10:\n",
    "                if oridata.iloc[i,j]=='S':\n",
    "                    oridata.iloc[i, j] = 0\n",
    "                if oridata.iloc[i,j]=='C':\n",
    "                    oridata.iloc[i, j] = 1\n",
    "                if oridata.iloc[i, j] == 'Q':\n",
    "                    oridata.iloc[i, j] = 2\n",
    "            else:\n",
    "                continue\n",
    "    return oridata\n",
    "def fillnan(oridata):\n",
    "    for i in range(0, oridata.shape[0]):\n",
    "        for j in range(0, oridata.shape[1]):\n",
    "                    # 如果是age列\n",
    "            if j==5:\n",
    "                if str(oridata.iloc[i,j])=='nan':\n",
    "                    oridata.iloc[i, j]=caculate_age(oridata.iloc[i,4],oridata.iloc[i,2],oridata.iloc[i,1])\n",
    "            if j==9:\n",
    "                if str(oridata.iloc[i,j])=='nan':\n",
    "                    oridata.iloc[i, j] = caculate_fare(oridata.iloc[i, 4],\n",
    "                                                                 oridata.iloc[i, 2])\n",
    "            if j==11:\n",
    "                if str(oridata.iloc[i,j])=='nan':\n",
    "                    oridata.iloc[i, j] = 0\n",
    "            else:\n",
    "                continue\n",
    "    return oridata\n",
    "\n",
    "def filltestnan(oridata):\n",
    "    for i in range(0, oridata.shape[0]):\n",
    "        for j in range(0, oridata.shape[1]):\n",
    "                    # 如果是age列\n",
    "            if j==4:\n",
    "                if str(oridata.iloc[i,j])=='nan':\n",
    "                    oridata.iloc[i, j]=caculate_test_age(oridata.iloc[i,3],oridata.iloc[i,1])\n",
    "            if j==8:\n",
    "                if str(oridata.iloc[i,j])=='nan':\n",
    "                    oridata.iloc[i, j] = caculate_fare(oridata.iloc[i, 3],\n",
    "                                                                 oridata.iloc[i, 1])\n",
    "            if j==10:\n",
    "                if str(oridata.iloc[i,j])=='nan':\n",
    "                    oridata.iloc[i, j] = 0\n",
    "            else:\n",
    "                continue\n",
    "    return oridata\n",
    "def cleandata(oridata):\n",
    "    return  fillnan(encode(oridata))\n",
    "def cleantestdata(oridata):\n",
    "    return filltestnan(encode_test(oridata))\n",
    "titanic_train_data=cleandata(titanic_train_data)\n",
    "titanic_test_data=cleantestdata(titanic_test_data)\n",
    "#print(titanic_train_data['Age'])\n",
    "\n",
    "#print(titanic_test_data['Embarked'])\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X_train,X_test,y_train,y_test=train_test_split(titanic_train_data[features],titanic_train_data['Survived'],test_size=0.25)\n",
    "tpot=TPOTClassifier(generations=5,population_size=20,verbosity=2)\n",
    "tpot.fit(X_train,y_train)\n",
    "predict_result=tpot.predict(titanic_test_data[features])\n",
    "print(predict_result)\n",
    "print(tpot.score(X_test,y_test))\n",
    "count=0\n",
    "for i in range(0,len(predict_result)):\n",
    "    if predict_result[i]==real_result.iloc[i,1]:\n",
    "        count+=1\n",
    "    else:\n",
    "        continue\n",
    "print(count)\n",
    "print(\"预测准确率：\")\n",
    "print(count/len(predict_result))\n",
    "\n",
    "\n",
    "#运行结果为：\n",
    "#Best pipeline: RandomForestClassifier(PolynomialFeatures(RobustScaler(input_matrix), degree=2, include_bias=False, interaction_only=False), bootstrap=True, criterion=gini, max_features=0.8500000000000001, min_samples_leaf=4, min_samples_split=11, n_estimators=100)\n",
    "#0.8923766816143498\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ID3决策树预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp']\n",
      "[1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1\n",
      " 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1\n",
      " 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1\n",
      " 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0\n",
      " 1]\n",
      "[1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0\n",
      " 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1\n",
      " 1 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1\n",
      " 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1\n",
      " 0 1 1 1 0 1 1 0 1 1 0]\n",
      "173\n",
      "ID3决策树预测准确率：\n",
      "0.4138755980861244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lyr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\n",
      "c:\\users\\lyr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\n",
      "c:\\users\\lyr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dvec=DictVectorizer(sparse=False)\n",
    "train_features=dvec.fit_transform(X_train.to_dict(orient='record'))\n",
    "print(dvec.feature_names_)\n",
    "# 构造ID3决策树\n",
    "clf = DecisionTreeClassifier(criterion='entropy',max_depth=8)\n",
    "# 决策树训练\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "test_features=dvec.transform(X_test.to_dict(orient='record'))\n",
    "# 决策树预测\n",
    "pred_labels = clf.predict(test_features)\n",
    "print(pred_labels)\n",
    "\n",
    "real_test_features=dvec.transform(titanic_test_data[features].to_dict(orient='record'))\n",
    "# 决策树预测\n",
    "real_pred_labels = clf.predict(real_test_features)\n",
    "print(real_pred_labels)\n",
    "# 得到决策树准确率(基于训练集)\n",
    "#acc_decision_tree = round(clf.score(train_features, y_train), 6)\n",
    "#print(u'score准确率为 %.4lf' % acc_decision_tree)\n",
    "count=0\n",
    "for i in range(0,len(real_pred_labels)):\n",
    "    if real_pred_labels[i]==real_result.iloc[i,1]:\n",
    "        count+=1\n",
    "    else:\n",
    "        continue\n",
    "print(count)\n",
    "print(\"ID3决策树预测准确率：\")\n",
    "print(count/len(real_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
