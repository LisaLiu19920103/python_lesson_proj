{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking1\t新零售中的“人、货、场”分别指的是什么？\n",
    "   答：人就是指客户群体，在新零售中对人进行分析就是要对用户进行人群分析，包括用户的年龄、职业、所在地、学历、手机品牌、兴趣爱好等等的特征进行分析，将用户进行划分，从而针对不同类型的用户去提供针对性的服务。货就是从产品的角度进行数据分析，分析产品的浏览量、点击量、订单量、入篮量、购买用户数等等，去分析产品特征，划定产品定位，指导工厂的生产，指导物流的配送，从商品生产到最终销售的整个环节，为产品生命周期分析及产品推广策略提供数据服务。场就是指用户的消费场所，转化成线上就是用户的导购页面，通过用户点击的热力图，能够去分析页面对用户吸引程度，从而指导运维或者管理员去优化页面布局，从而更好的提升用户使用的友好性，提升客户点击率，提高转化率。\n",
    "### Thinking2\tAIPL与传统的品牌资产评估有何区别？\n",
    "答：传统的品牌资产评估都是对“人群资产”定性的描述，而AIPL通过认知（广告曝光、公域页面曝光、无品牌倾向搜索）、兴趣（广告点击、粉丝互动、店铺浏览、品牌倾向搜索、关注/收藏/加购）、购买、忠诚（反复购买/主动分享/正面评论）四个维度来进行定量分析，让品牌方能够对自己产品的“人群资产”有更加直观的感受，用这些定量分析数据去更好的支撑决策，去调整运营策略。     \n",
    "### Thinking3\t请列举一例生活工作中存在的帕累托法则\n",
    "答：在工作中，可能公司的80%的利润可能来自于公司主打的20%的主要产品。   \n",
    "### Thinking4\t请简述GBDT与XGBoost的区别？\n",
    "答：GBDT（Gradient Boosting Decision Tree）是通过拟合残差来学习的决策树，它的基分类器是CART回归树。XGBoost是一个大规模分布式的GBDT库，XGBoost通过引入正则化项来控制模型的复杂度，避免模型在学习中的过拟合，它的损失函数是二阶泰勒展开，同时用到了一阶和二阶导数，能够加速收敛，XGBoost除了支持CART基分类器，同时还支持线性分类器，xgboost借鉴了随机森林的做法，能够进行列采样，降低过拟合，减少计算，此外xgboost工具支持并行运算，各个特征的增益计算能并行进行，最终选择信息增益最大的特征去做分裂。\n",
    "### Thinking5\t如何处理神经网络中的过拟合问题？\n",
    "答：1.简化模型，避免层数过深过复杂。2.早停法，提前定义当loss在多少个迭代内不下降了就提前停止模型的训练。3.避免数据量小，如果数据比较少，通过各种方法增加正负样本量。4.使用正则化项，控制模型复杂度。5.随机丢弃法，每一次迭代过程中随机地丢弃神经网络中的神经元。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
